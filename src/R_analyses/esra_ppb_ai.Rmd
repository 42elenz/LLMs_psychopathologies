---
title: "LLM PPB analysis for paper"
output:
  word_document: default
  html_notebook: default
---
```{r packages, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(lme4)
library(dplyr)
library(furrr)
```


```{r Loading data, echo=FALSE}
df <- read_csv("r_export_mixed_model_data_simple.csv")

df <- df %>% mutate(across(everything(), as.factor)) %>%
  mutate(Correct = as.integer(as.character(Correct))) %>% 
  #rbind(.,df_aug) %>% 
  select(-c("Model_name", "ausbildung_fertig"))

df2 <- read_csv("disagreement_data.csv") %>% 
  select(-c("final_value", "correct_reference")) %>% 
  mutate(strategy = as.factor(strategy_chosen), item_id = as.factor(item_id), video_id = as.factor(video_id), pair_id=as.factor(pair_id)) %>% 
  select(-strategy_chosen)
```

```{r Data overview, eval=FALSE, echo=FALSE}
df %>% filter(Ratertype=="human") %>% 
  group_by(ID) %>% 
  summarise(percent_correct = mean(as.numeric(as.character(Correct)))) %>% 
  pull(percent_correct) %>% 
  hist()

df %>% filter(Ratertype=="human") %>% 
  group_by(ID) %>% 
  summarise(sumscore = sum(as.numeric(as.character(Correct)))) %>% 
  pull(sumscore) %>% 
  hist()

df %>% filter(Ratertype=="human", Video_id==7) %>% 
  group_by(ID) %>% 
  summarise(percent_correct = mean(as.numeric(as.character(Correct)))) %>% 
  pull(percent_correct) %>% 
  hist()

df %>% filter(Ratertype=="human", Video_id==7) %>% 
  group_by(ID) %>% 
  summarise(n=n())

df %>% filter(Ratertype=="human", Video_id==8) %>% 
  group_by(ID) %>% 
  summarise(percent_correct = mean(as.numeric(as.character(Correct)))) %>% 
  pull(percent_correct) %>% 
  hist()

df %>% filter(Ratertype=="human", Video_id==8) %>% 
  group_by(ID) %>% 
  summarise(n=n())

df %>% filter(Ratertype=="human", Video_id==9) %>% 
  group_by(ID) %>% 
  summarise(percent_correct = mean(as.numeric(as.character(Correct)))) %>% 
  pull(percent_correct) %>% 
  hist()

df %>% filter(Ratertype=="human", Video_id==9) %>% 
  group_by(ID) %>% 
  summarise(n=n())
```

Overall comparison AI vs human based on simulation

```{r simulation, echo=FALSE}
df <- df %>% mutate(Correct = as.numeric(as.character(Correct)))

df_train <- df %>% filter(Ratertype == "human")

m <- glmer(
  Correct ~ 1 + Video_id +
    (1 | ID) +
    (1 | Item) +
    (1 | Video_id:Item),
  data = df_train,
  family = binomial,
  control = glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5))
)

df_target <- df %>% filter(Ratertype == "AI")

df_target <- df_target %>%
  mutate(pred = predict(m, newdata = ., re.form = ~(1 | Item) + (1 | Video_id:Item), type = "response"))

observed_sum <- sum(df_target$Correct)
set.seed(1)
n_sim <- 10000

sim_scores <- replicate(n_sim, {
  sum(rbinom(n = nrow(df_target), size = 1, prob = df_target$pred))
})

model_based_p_one_sided <- mean(sim_scores >= observed_sum)
model_based_p_two_sided_approx <- 2 * min(mean(sim_scores >= observed_sum), mean(sim_scores <= observed_sum))

expected_mean <- mean(sim_scores/300)
expected_sd   <- sd(sim_scores/300)
ci            <- quantile((sim_scores/300), c(.025, .975))

summary(m)
```

```{r model check, echo=FALSE}
overdisp_fun <- function(model) {
  rdf <- df.residual(model)
  rp <- residuals(model, type="pearson")
  sum(rp^2)/rdf
}
overdisp_fun(m)
```

Quasi experiment synergistic strategies

```{r accuracy as test statistic, echo=FALSE}
obs_stat <- df2 %>%
  group_by(strategy) %>%
  summarise(acc = mean(as.numeric(is_correct))) %>%
  pivot_wider(names_from = strategy, values_from = acc) %>%
  mutate(
    llm_vs_random   = ai_always - human_only,
    third_vs_random = human_only_supervision - human_only
  ) %>%
  select(llm_vs_random, third_vs_random)

obs_stat_7 <- df2 %>%
  filter(video_id==7) %>% 
  group_by(strategy) %>%
  summarise(acc = mean(as.numeric(is_correct))) %>%
  pivot_wider(names_from = strategy, values_from = acc) %>%
  mutate(
    llm_vs_random   = ai_always - human_only,
    third_vs_random = human_only_supervision - human_only
  )

obs_stat_8 <- df2 %>%
  filter(video_id==8) %>% 
  group_by(strategy) %>%
  summarise(acc = mean(as.numeric(is_correct))) %>%
  pivot_wider(names_from = strategy, values_from = acc) %>%
  mutate(
    llm_vs_random   = ai_always - human_only,
    third_vs_random = human_only_supervision - human_only
  )

obs_stat_9 <- df2 %>%
  filter(video_id==9) %>% 
  group_by(strategy) %>%
  summarise(acc = mean(as.numeric(is_correct))) %>%
  pivot_wider(names_from = strategy, values_from = acc) %>%
  mutate(
    llm_vs_random   = ai_always - human_only,
    third_vs_random = human_only_supervision - human_only
  )
```

```{r tables, eval=FALSE}

df2 %>% 
  filter(video_id==7) %>% 
  select(is_correct, strategy) %>% 
  droplevels() %>% 
  table()

df2 %>% 
  filter(video_id==8) %>% 
  select(is_correct, strategy) %>% 
  droplevels() %>% 
  table()

df2 %>% 
  filter(video_id==9) %>% 
  select(is_correct, strategy) %>% 
  droplevels() %>% 
  table()

```

```{r permutation function}
perm_test_video <- function(df, video, B = 5) {

  df_v <- df %>% filter(video_id == video)

  obs <- df_v %>%
    group_by(strategy) %>%
    summarise(acc = mean(is_correct), .groups = "drop") %>%
    pivot_wider(names_from = strategy, values_from = acc) %>%
    mutate(
      llm_vs_human   = ai_always - human_only,
      third_vs_human = human_only_supervision - human_only
    )

  permute_once_v <- function() {
    df_v %>%
      group_by(video_id, item_id, pair_id) %>%
      mutate(
        strategy = if (n_distinct(is_correct) > 1)
          sample(strategy)
        else
          strategy
      ) %>%
      ungroup()
  }

  perm <- replicate(B, {
    df_p <- permute_once_v()

    df_p %>%
      group_by(strategy) %>%
      summarise(acc = mean(is_correct), .groups = "drop") %>%
      pivot_wider(names_from = strategy, values_from = acc) %>%
      mutate(
        llm_vs_human   = ai_always - human_only,
        third_vs_human = human_only_supervision - human_only
      )
  }, simplify = FALSE) %>% bind_rows()

  tibble(
    video_id = video,
    contrast = c("LLM vs human", "Supervisor vs human"),
    estimate = c(obs$llm_vs_human, obs$third_vs_human),
    p_value = c(
      (sum(abs(perm$llm_vs_human) >= abs(obs$llm_vs_human)) + 1) / (B + 1),
      (sum(abs(perm$third_vs_human) >= abs(obs$third_vs_human)) + 1) / (B + 1)
    )
  )
}
```

```{r run permutation test, eval=FALSE}
set.seed(1)
plan(multisession)

results_video <- future_map_dfr(
  unique(df2$video_id),
  ~ perm_test_video(df2, .x, B = 5000),
  .options = furrr_options(seed = TRUE)
)

saveRDS(results_video, file = "results_video.rds")
```

```{r load results of permutation test}
results_video <-
readRDS("results_video.rds")
```

## Methods
### Overall comparison LLM vs human
Most participants rated only one of the videos, while the AI rated all three. The videos and the items, as well as the items depending on the video, had varying difficulties. Thus in order to compare the performance of the AI to the human performance over all three videos, we fitted a generalized linear mixed-effects model with a binomial link function to predict trial-level response accuracy. The model included a fixed intercept and a fixed effect of video, as well as random intercepts for participants, items, and item–video combinations.

Correct∼Video+(1∣ID)+(1∣Item)+(1∣Video:Item),logit link

We used the fitted model to generate a reference distribution for the total score under the assumption that responses follow the human performance distribution (simulated n = 10000. The AI score was then compared against this model-based reference distribution.

### Comparison of disagreement-resolution strategies
To compare disagreement-resolution strategies, we conducted a permutation test separate for each video based on the items with disagreement between the two raters as only in these cases the different strategies actually play a role. For each unique combination of item, and rater pairing, three adjudicated responses were available, corresponding to the three strategies (random selection, experienced clinician, LLM).
Under the null hypothesis of no strategy effect, strategy labels are exchangeable within each item–pairing unit. We therefore generated the null distributions for each of the videos by randomly permuting strategy labels within each such unit, while keeping the observed responses, item identity and pairing fixed. This permutation scheme preserves video-specific item difficulty and pairing-related dependencies.
The test statistic was the difference in mean accuracy between strategies (LLM vs random selection; experienced clinician vs random selection). Two-sided p-values were obtained as the proportion of permutations yielding an absolute test statistic at least as large as the observed value. Results are based on 5,000 permutations.

## Results
### Overall comparison LLM vs human
```{r create plot data, echo=FALSE}
plot_df <- tibble(
  sim_score = sim_scores
)
```

```{r fig-density, echo=FALSE}
ggplot(plot_df, aes(x = sim_score / 300)) +
  geom_density(adjust = 1.2) +
  geom_vline(
    xintercept = observed_sum / 300,
    linetype = "dashed",
    linewidth = 1
  ) +
  geom_vline(
    xintercept = ci,
    linetype = "dotted"
  ) +
  labs(
    x = "Proportion correct (human reference model)",
    y = "Density"
  ) +
  theme_minimal()


```

The AI achieved a total accuracy of `r observed_sum/300` (dashed line). Under the fitted human model the expected total accuracy was `r round(mean(sim_scores/300), 2)` (SD = `r round(sd(sim_scores), 2)`;
95% simulation interval (dotted lines): `r round(quantile(sim_scores / 300, .025), 3)`–`r round(quantile(sim_scores / 300, .975), 3)`).
Only `r round(100 * mean(sim_scores >= observed_sum), 1)`% of simulated scores were equal to or larger than the observed AI score.

### Comparison of disagreement-resolution strategies 
As the permutation test is based on the items with rater disagreement consequentally the accuracy reported here is in regards to these items only. Both adjudication via the LLM and the experienced clinician yielded significantly higher accuracies than random selection (Depression video: LLM accuracy = `r round(obs_stat_7$ai_always,3)`, experienced clinician accuracy = `r round(obs_stat_7$human_only_supervision,3)`, random human accuracy = `r round(obs_stat_7$human_only,3)`, Δ accuracy LLM vs random = `r round(obs_stat_7$llm_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==7, contrast=="LLM vs human") %>% pull(p_value),4)`, Δ accuracy experienced clinician vs random = `r round(obs_stat_7$third_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==7, contrast=="Supervisor vs human") %>% pull(p_value),4)`; Mania video: LLM accuracy = `r round(obs_stat_8$ai_always,3)`, experienced clinician accuracy = `r round(obs_stat_8$human_only_supervision,3)`, random human accuracy = `r round(obs_stat_8$human_only,3)`, Δ accuracy LLM vs random = `r round(obs_stat_8$llm_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==8, contrast=="LLM vs human") %>% pull(p_value),4)`, Δ accuracy experienced clinician vs random = `r round(obs_stat_8$third_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==8, contrast=="Supervisor vs human") %>% pull(p_value),4)`; Schizophrenia video: LLM accuracy = `r round(obs_stat_9$ai_always,3)`, experienced clinician accuracy = `r round(obs_stat_9$human_only_supervision,3)`, random human accuracy = `r round(obs_stat_9$human_only,3)`, Δ accuracy LLM vs random = `r round(obs_stat_9$llm_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==9, contrast=="LLM vs human") %>% pull(p_value),4)`, Δ accuracy experienced clinician vs random = `r round(obs_stat_9$third_vs_random,3)`, permutation p = `r round(results_video %>% filter(video_id==9, contrast=="Supervisor vs human") %>% pull(p_value),4)`).
